# -*- coding: utf-8 -*-
"""Unsupervised_Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zIj1a2Hdkm5BIpA0xaYN1uyFMCU2wtep
"""

#Install Kaggle
!pip install -q kaggle

from google.colab import files
files.upload()

#Create a kaggle folder
! mkdir ~/.kaggle

#copy the kaggle.json to folder created
! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

! kaggle datasets download -d alanherrerat/unsupervised-fruits-dataset

!unzip \*.zip  && rm *.zip

# Commented out IPython magic to ensure Python compatibility.
import os
import zipfile
import random
import shutil
import numpy as np
from shutil import copyfile

# %matplotlib inline
import matplotlib.image as mpimg
import matplotlib.pyplot as plt

import tensorflow as tf
from google.colab import files
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def make_dir(PATH):
  if not os.path.exists(PATH):
      os.mkdir(PATH)
      return PATH
  else:
    shutil.rmtree(PATH)
    os.mkdir(PATH)
    return PATH

try:
    base_dir = '/tmp'
    fruit_dir = make_dir(os.path.join(base_dir, 'fruit-dataset'))
    train_dir = make_dir(os.path.join(fruit_dir, 'train'))
    validation_dir = make_dir(os.path.join(fruit_dir, 'val'))
    test_dir = make_dir(os.path.join(fruit_dir, 'test'))
    preview_dir = make_dir(os.path.join(fruit_dir, 'preview'))

except OSError:
    pass

from PIL import Image

def split_data(SOURCE='', TRAINING='', VALIDATION='', SPLIT_SIZE=0):
  data = os.listdir(SOURCE)
  random_data = random.sample(data, len(data))

  train_size = len(data)*SPLIT_SIZE

  for i, filename in enumerate(random_data):
    filepath = os.path.join(SOURCE, filename)
    if os.path.getsize(filepath) > 0:
      if i < train_size:
        copyfile(filepath, os.path.join(TRAINING, filename))
        # img = Image.open(os.path.join(TRAINING, filename)).convert('L')
        # img.save(os.path.join(TRAINING, filename))
      else:
        copyfile(filepath, os.path.join(VALIDATION, filename))
        # img = Image.open(os.path.join(VALIDATION, filename)).convert('L')
        # img.save(os.path.join(VALIDATION, filename))

dataset_train_dir = '/content/dataset/train'
dataset_test_dir = '/content/dataset/test'

import shutil

# Rutas de las carpetas
source_folder = '/content/dataset/train'
destination_folder = '/tmp/fruit-dataset/train'

source_folder2 = '/content/dataset/test'
destination_folder2 = '/tmp/fruit-dataset/test'

source_folder3 = '//content/dataset/valid'
destination_folder3 = '/tmp/fruit-dataset/val'



# Eliminar la carpeta de destino si ya existe
shutil.rmtree(destination_folder, ignore_errors=True)

# Eliminar la carpeta de destino si ya existe
shutil.rmtree(destination_folder2, ignore_errors=True)

# Eliminar la carpeta de destino si ya existe
shutil.rmtree(destination_folder3, ignore_errors=True)

# Copiar el contenido de una carpeta a otra
shutil.copytree(source_folder, destination_folder)

# Copiar el contenido de una carpeta a otra
shutil.copytree(source_folder2, destination_folder2)

# Copiar el contenido de una carpeta a otra
shutil.copytree(source_folder3, destination_folder3)

fruits_train_dir = '/tmp/fruit-dataset/train'
fruits_val_dir = '/tmp/fruit-dataset/test'
fruits_test_dir = '/tmp/fruit-dataset/val'

print(len(os.listdir(fruits_train_dir)))
print(len(os.listdir(fruits_val_dir)))
print(len(os.listdir(fruits_test_dir)))

train_datagen = ImageDataGenerator(
    rescale=1./255,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=[0.5, 1.0],
    rotation_range=90,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='reflect'
)

validation_datagen = ImageDataGenerator(
    rescale=1./255
)

import math
path_aug = os.path.join(fruits_train_dir, os.listdir(fruits_train_dir)[-1])
img_augmentation = image.load_img(path_aug)
x_aug = image.img_to_array(img_augmentation)
x_aug = x_aug.reshape((1,) + x_aug.shape)

i = 0
for batch in train_datagen.flow(x_aug, batch_size=1, save_to_dir=preview_dir, save_prefix='fruits', save_format='jpeg'):
    i += 1
    if i >= 20:
        break

preview_img = os.listdir(preview_dir)

plt.figure(figsize=(15, 15))
for n in range(len(preview_img)):
  plt.subplot(math.ceil(len(preview_img)/4), 4, n+1)
  plt.subplots_adjust(hspace = 0.3)
  plt.imshow(image.load_img(os.path.join(preview_dir, preview_img[n]),
                            color_mode="rgb",
                            target_size=(150, 150),
                            interpolation="nearest"))
  plt.axis('off')
plt.show()

for fn in preview_img:
  os.system(f'rm {os.path.join(preview_dir, fn)}')

import pandas as pd
import os

# Obtén la lista de nombres de archivos en el directorio
file_names = os.listdir('/tmp/fruit-dataset/train')

# Crea un DataFrame con la ruta de cada imagen y una etiqueta única para cada imagen
df = pd.DataFrame({
    'filename': file_names,
    'class': [f'image_{i}' for i in range(len(file_names))]
})

# Imprime algunas filas del DataFrame para verificar
print(df.head())

# Utiliza flow_from_dataframe para crear el generador de flujo de datos
unsupervised_generator = train_datagen.flow_from_dataframe(
    dataframe=df,
    directory='/tmp/fruit-dataset/train',
    x_col='filename',
    y_col='class',
    batch_size=32,
    color_mode="rgb",
    shuffle=False,  # Mantener el orden original de las imágenes
    target_size=(150, 150),
    class_mode=None  # No hay clases en el enfoque no supervisado
)

class MyCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('validation_loss') < 0.1):  # Ajusta según tus necesidades
            print("\nReached a satisfactory performance. Stop Training")
            self.model.stop_training = True

callbacks = MyCallback()

import numpy as np
from sklearn.cluster import KMeans
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LeakyReLU, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Aumento de la complejidad de la red y ajuste de dropout
model = Sequential([
    Conv2D(32, (3, 3), input_shape=(150, 150, 3)),
    LeakyReLU(alpha=0.1),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3)),
    LeakyReLU(alpha=0.1),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.05)),  # Aumento de neuronas
    LeakyReLU(alpha=0.1),
    Dropout(0.3),  # Ajuste de la tasa de dropout
    Dense(256, kernel_regularizer=tf.keras.regularizers.l2(0.05)),  # Capa adicional
    LeakyReLU(alpha=0.1),
    Dropout(0.3),  # Ajuste de la tasa de dropout
])

# Compilar el modelo con un optimizador Adam y la pérdida 'mse'
model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')  # Ajustar la tasa de aprendizaje

# Obtener las activaciones de la capa latente para todo el conjunto de datos
latent_space_train = model.predict(unsupervised_generator)

# Ajustar K-Means con diferentes parámetros
num_clusters = 8  # Ajusta según el número de clases conocidas
kmeans = KMeans(n_clusters=num_clusters, n_init=20, random_state=42)
clusters = kmeans.fit_predict(latent_space_train)

# Evaluar los resultados (por ejemplo, visualizar algunas imágenes con sus clusters)
# ... (código de visualización)

import matplotlib.pyplot as plt
import numpy as np

# Asigna las etiquetas de cluster al DataFrame original
df['cluster'] = clusters

# Visualiza algunas imágenes junto con sus etiquetas de cluster
num_samples = 10
selected_samples = df.sample(num_samples)

plt.figure(figsize=(15, 8))
for i, (_, row) in enumerate(selected_samples.iterrows()):
    plt.subplot(2, 5, i + 1)
    img_path = os.path.join('/tmp/fruit-dataset/train', row['filename'])
    img = plt.imread(img_path)
    plt.imshow(img)
    plt.title(f'Cluster: {row["cluster"]}')
    plt.axis('off')

plt.show()